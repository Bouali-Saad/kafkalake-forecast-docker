# KafkaLake Forecast â€” Dockerized Data Engineering & ML Pipeline

KafkaLake Forecast is a **production-style data engineering project** that demonstrates how to build a **real-time streaming pipeline with Kafka**, process data using **Spark Structured Streaming**, store it in a **Delta Lakehouse**, orchestrate workflows with **Airflow**, validate data quality with **Great Expectations**, and train a **machine learning model for demand forecasting**.

This project is built **step by step**, following real-world data engineering best practices.

---

## ğŸ¯ Project Goal
Predict product demand (J+1) using real-time and historical sales data in order to:
- improve stock planning
- reduce shortages
- support business decisions

---

## ğŸ§± Tech Stack
- **Kafka** â€“ real-time streaming ingestion
- **Spark Structured Streaming (PySpark)** â€“ data processing
- **Delta Lake** â€“ Lakehouse architecture (Bronze / Silver / Gold)
- **MinIO (S3)** â€“ object storage
- **Airflow** â€“ pipeline orchestration
- **Great Expectations** â€“ data quality validation
- **XGBoost / LightGBM** â€“ machine learning forecasting
- **FastAPI** â€“ model serving
- **Docker & Docker Compose** â€“ full environment setup

---

## ğŸ—ï¸ High-Level Architecture
1. Sales events are produced to **Kafka**
2. Spark Streaming consumes Kafka data â†’ **Bronze Delta tables**
3. Airflow runs daily jobs:
   - Bronze â†’ Silver (cleaning & validation)
   - Silver â†’ Gold (feature engineering)
   - Train & evaluate ML model
   - Promote best model to production
4. FastAPI serves predictions through an API

---

## ğŸ—‚ï¸ Lakehouse Layers
- **Bronze**: raw Kafka events
- **Silver**: cleaned and validated data
- **Gold**: aggregated features for ML

---

## â›“ï¸ Airflow DAG (Daily)
- `bronze_to_silver`
- `validate_data_quality`
- `build_gold_features`
- `train_ml_model`
- `evaluate_model`
- `promote_model`
- `api_smoke_test`

---

## ğŸš§ Project Status
This project is under active development:

- [x] Repository initialization
- [ ] Dockerized base stack (Kafka, Spark, MinIO, Airflow)
- [ ] Kafka producer
- [ ] Spark streaming ingestion
- [ ] Data quality checks
- [ ] ML training & evaluation
- [ ] API serving

---

## ğŸ‘¤ Author
**Saad Bouali**  
Master Big Data & Cloud Computing  
ğŸ“ Casablanca, Morocco  
ğŸ”— LinkedIn: https://linkedin.com/in/saad-bouali  
ğŸ“§ Email: saadbouali2020@gmail.com
